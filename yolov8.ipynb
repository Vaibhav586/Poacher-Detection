{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV dataset updated at C:/Users/vikas/OneDrive/Documents/Poacher_Detection_CNN/data\\final_updated_data.csv\n",
      "Batch of images shape: torch.Size([32, 3, 224, 224])\n",
      "Batch of labels: tensor([1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "        1, 0, 1, 1, 0, 1, 1, 0])\n",
      "Epoch [1/10], Loss: 2.5566\n",
      "Epoch [2/10], Loss: 0.4205\n",
      "Epoch [3/10], Loss: 0.3506\n",
      "Epoch [4/10], Loss: 0.2635\n",
      "Epoch [5/10], Loss: 0.2153\n",
      "Epoch [6/10], Loss: 0.1799\n",
      "Epoch [7/10], Loss: 0.1363\n",
      "Epoch [8/10], Loss: 0.1013\n",
      "Epoch [9/10], Loss: 0.0743\n",
      "Epoch [10/10], Loss: 0.0421\n",
      "Poacher detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikas\\AppData\\Local\\Temp\\ipykernel_27816\\891089453.py:132: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('poacher_detector.pth'))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.io import read_image\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# Define main dataset directory\n",
    "dataset_dir = \"C:/Users/vikas/OneDrive/Documents/Poacher_Detection_CNN/data\"\n",
    "poacher_dir = os.path.join(dataset_dir, \"poacher\")\n",
    "non_poacher_dir = os.path.join(dataset_dir, \"non_poacher\")\n",
    "csv_path = os.path.join(dataset_dir, \"final_updated_data.csv\")\n",
    "\n",
    "# Initialize lists to store file paths and labels\n",
    "file_paths = []\n",
    "labels = []\n",
    "\n",
    "# Function to collect image paths and labels from a directory\n",
    "def collect_images(directory, label):\n",
    "    if os.path.exists(directory):\n",
    "        for filename in os.listdir(directory):\n",
    "            if filename.lower().endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "                file_paths.append(os.path.join(directory, filename))\n",
    "                labels.append(label)\n",
    "\n",
    "# Collect poacher and non-poacher images\n",
    "collect_images(poacher_dir, \"poacher\")\n",
    "collect_images(non_poacher_dir, \"non-poacher\")\n",
    "\n",
    "# Check if the CSV already exists and append new entries\n",
    "if os.path.exists(csv_path):\n",
    "    existing_df = pd.read_csv(csv_path)\n",
    "    new_df = pd.DataFrame({\"file_path\": file_paths, \"label\": labels})\n",
    "    \n",
    "    # Merge and drop duplicates to avoid re-adding existing entries\n",
    "    combined_df = pd.concat([existing_df, new_df]).drop_duplicates(subset=\"file_path\").reset_index(drop=True)\n",
    "else:\n",
    "    combined_df = pd.DataFrame({\"file_path\": file_paths, \"label\": labels})\n",
    "\n",
    "# Save the combined DataFrame as CSV\n",
    "combined_df.to_csv(csv_path, index=False)\n",
    "print(f\"CSV dataset updated at {csv_path}\")\n",
    "\n",
    "# Define the custom Dataset class\n",
    "class PoacherDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data.iloc[idx, 0]\n",
    "        # Read the image as a tensor\n",
    "        image = read_image(img_path)\n",
    "        # Convert the tensor to a PIL Image\n",
    "        image = transforms.ToPILImage()(image)\n",
    "        # Convert image to RGB to handle inconsistent channels\n",
    "        image = image.convert(\"RGB\")\n",
    "        # Encode labels as integers (1 for poacher, 0 for non-poacher)\n",
    "        label = 1 if self.data.iloc[idx, 1].strip().lower() == \"poacher\" else 0\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Define transformations and load dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Lambda(lambda image: image.convert(\"RGB\")),  # Ensure all images are RGB\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Instantiate the dataset and dataloader\n",
    "dataset = PoacherDataset(csv_file=csv_path, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Verify a batch from the dataloader\n",
    "for images, labels in dataloader:\n",
    "    print(f\"Batch of images shape: {images.shape}\")\n",
    "    print(f\"Batch of labels: {labels}\")\n",
    "    break\n",
    "\n",
    "# Define a simple CNN model for classification\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 56 * 56, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.ReLU()(self.conv1(x))\n",
    "        x = nn.MaxPool2d(kernel_size=2, stride=2)(x)\n",
    "        x = nn.ReLU()(self.conv2(x))\n",
    "        x = nn.MaxPool2d(kernel_size=2, stride=2)(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define the number of epochs\n",
    "num_epochs = 10\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for images, labels in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(dataloader):.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'poacher_detector.pth')\n",
    "\n",
    "# Load the saved model for inference\n",
    "model.load_state_dict(torch.load('poacher_detector.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Prediction function\n",
    "def predict_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "    return \"Poacher detected\" if predicted.item() == 1 else \"Non-poacher detected\"\n",
    "\n",
    "# Test the prediction\n",
    "test_image_path = r\"C:\\Users\\vikas\\OneDrive\\Documents\\Poacher_Detection_CNN\\data\\poacher\\IMG_2887.JPG\"\n",
    "result = predict_image(test_image_path)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define a simple CNN model for classification\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)  # First convolutional layer\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)  # Second convolutional layer\n",
    "        self.fc1 = nn.Linear(32 * 56 * 56, 128)  # Fully connected layer (adjust size for your input dimensions)\n",
    "        self.fc2 = nn.Linear(128, 2)  # Output layer with 2 classes: poacher and non-poacher\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.ReLU()(self.conv1(x))  # Apply ReLU activation after conv1\n",
    "        x = nn.MaxPool2d(kernel_size=2, stride=2)(x)  # Apply max pooling\n",
    "        x = nn.ReLU()(self.conv2(x))  # Apply ReLU activation after conv2\n",
    "        x = nn.MaxPool2d(kernel_size=2, stride=2)(x)  # Apply max pooling\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor for the fully connected layer\n",
    "        x = nn.ReLU()(self.fc1(x))  # Apply ReLU after fc1\n",
    "        x = self.fc2(x)  # Final output layer\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss()  # Loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Optimizer with learning rate 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.8674\n",
      "Epoch [2/10], Loss: 1.2499\n",
      "Epoch [3/10], Loss: 0.5666\n",
      "Epoch [4/10], Loss: 0.5456\n",
      "Epoch [5/10], Loss: 0.2754\n",
      "Epoch [6/10], Loss: 0.2523\n",
      "Epoch [7/10], Loss: 0.1609\n",
      "Epoch [8/10], Loss: 0.1546\n",
      "Epoch [9/10], Loss: 0.0939\n",
      "Epoch [10/10], Loss: 0.0759\n"
     ]
    }
   ],
   "source": [
    "# Define the number of epochs (number of times we go through the entire dataset)\n",
    "num_epochs = 10  # Adjust as needed\n",
    "\n",
    "# Loop over each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0  # To keep track of the total loss for the epoch\n",
    "    for images, labels in dataloader:\n",
    "        # Clear gradients before each step\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass: compute model output\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass: compute gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate loss\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # Print the average loss for the epoch\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(dataloader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as poacher_detector.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the model's state dictionary to a file\n",
    "torch.save(model.state_dict(), 'poacher_detector.pth')\n",
    "print(\"Model saved as poacher_detector.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test images: 98.82%\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode (disables dropout, etc.)\n",
    "model.eval()\n",
    "\n",
    "# Track correct predictions\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Turn off gradients for faster computation and to save memory\n",
    "with torch.no_grad():\n",
    "    for images, labels in dataloader:  # Use test or validation dataloader here if available\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)  # Get the index of the max log-probability\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy of the model on the test images: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikas\\AppData\\Local\\Temp\\ipykernel_27816\\186802217.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('poacher_detector.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimpleCNN(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=100352, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the saved model\n",
    "model = SimpleCNN()\n",
    "model.load_state_dict(torch.load('poacher_detector.pth'))\n",
    "model.eval()  # Set the model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define the same transformations used in training\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize the image to match the input size of the model\n",
    "    transforms.ToTensor()           # Convert the image to a tensor\n",
    "])\n",
    "\n",
    "# Load and preprocess the image\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path)       # Open the image file\n",
    "    image = transform(image)             # Apply transformations\n",
    "    image = image.unsqueeze(0)           # Add batch dimension (1, C, H, W)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict function\n",
    "def predict_image(image_path):\n",
    "    # Preprocess the image\n",
    "    image = preprocess_image(image_path)\n",
    "    \n",
    "    # Forward pass: get the model output\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        _, predicted = torch.max(output, 1)  # Get the predicted class index (0 for non-poacher, 1 for poacher)\n",
    "\n",
    "    # Map the prediction to the corresponding label\n",
    "    if predicted.item() == 1:\n",
    "        return \"Poacher detected\"\n",
    "    else:\n",
    "        return \"Non-poacher detected\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poacher detected\n"
     ]
    }
   ],
   "source": [
    "# Path to the image you want to test\n",
    "image_path = image_path = r\"C:\\Users\\vikas\\OneDrive\\Documents\\Poacher_Detection_CNN\\data\\poacher\\IMG_2887.JPG\"\n",
    "\n",
    "# Run the detection\n",
    "result = predict_image(image_path)\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mll",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
